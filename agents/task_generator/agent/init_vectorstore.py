import os
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import SentenceTransformerEmbeddings

# Script path
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# File paths
EXAMPLES_PATH = os.path.join(BASE_DIR, "../c_knowledge_data/Tasks_examples.md")
VECTORSTORE_PATH = os.path.join(BASE_DIR, "../vector_db/task_generation_faiss")

# Embeddings model
embeddings = SentenceTransformerEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)


# Load example tasks from markdown file
def load_from_markdown():
    example_tasks = []

    if not os.path.exists(EXAMPLES_PATH):
        print(f"‚ùå –§–∞–π–ª {EXAMPLES_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return []

    with open(EXAMPLES_PATH, "r", encoding="utf-8") as f:
        content = f.read()
        lines = content.split("\n")
        current_task = ""

        for line in lines:
            if line.strip():
                current_task += line + "\n"
            else:
                if current_task.strip():
                    example_tasks.append(current_task.strip())
                    current_task = ""

        if current_task.strip():
            example_tasks.append(current_task.strip())

    return example_tasks


# Initialize vector store
example_tasks = load_from_markdown()

if not example_tasks:
    print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã. –ü—Ä–æ–≤–µ—Ä—å —Ñ–∞–π–ª Tasks_examples.md")
else:
    print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(example_tasks)} –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ Tasks_examples.md")
    os.makedirs(VECTORSTORE_PATH, exist_ok=True)
    vectorstore = FAISS.from_texts(example_tasks, embeddings)
    vectorstore.save_local(VECTORSTORE_PATH)
    print("‚úÖ –ò–Ω–¥–µ–∫—Å —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")
    print(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {VECTORSTORE_PATH}")
