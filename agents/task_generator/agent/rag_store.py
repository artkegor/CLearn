import os
import hashlib
from typing import List
from langchain.schema import Document

from logging_config import setup_logging
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader, DirectoryLoader
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores import FAISS

logger = setup_logging()


def get_embeddings(model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
    return SentenceTransformerEmbeddings(model_name=model_name)


class RAGStore:
    def __init__(self,
                 vector_db_dir: str = "./agents/task_generator/vector_db",
                 knowledge_base_dir: str = "./agents/task_generator/c_knowledge_data",
                 embeddings_model: str = "sentence-transformers/all-MiniLM-L6-v2"
                 ):
        self.vector_db_dir = vector_db_dir
        self.knowledge_base_dir = knowledge_base_dir
        self.embeddings = get_embeddings(embeddings_model)
        os.makedirs(self.vector_db_dir, exist_ok=True)

    def _built_in_examples(self) -> List[Document]:
        """ Extended pack of built-in C programming examples in Russian """
        examples = {
            "1_1": """–¢–ï–ú–ê: –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
–°–õ–û–ñ–ù–û–°–¢–¨: –õ–µ–≥–∫–∞—è

–ó–ê–î–ê–ù–ò–ï:
–ù–∞–ø–∏—à–∏—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—É, –∫–æ—Ç–æ—Ä–∞—è —Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–≤–∞ —Ü–µ–ª—ã—Ö —á–∏—Å–ª–∞ –∏ –≤—ã–≤–æ–¥–∏—Ç –∏—Ö —Å—É–º–º—É.

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–î–≤–∞ —Ü–µ–ª—ã—Ö —á–∏—Å–ª–∞ a –∏ b (1 ‚â§ a, b ‚â§ 1000), –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–µ –≤ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª

–í–´–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–û–¥–Ω–æ —á–∏—Å–ª–æ - —Å—É–º–º–∞ a –∏ b

–ü–†–ò–ú–ï–†:
–í—Ö–æ–¥:
5 3
–í—ã—Ö–æ–¥:
8

–ü–û–î–°–ö–ê–ó–ö–ê:
–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ scanf("%d %d", &a, &b) –¥–ª—è –≤–≤–æ–¥–∞ –∏ printf("%d\\n", sum) –¥–ª—è –≤—ã–≤–æ–¥–∞.""",

            "1_2": """–¢–ï–ú–ê: –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
–°–õ–û–ñ–ù–û–°–¢–¨: –°—Ä–µ–¥–Ω—è—è

–ó–ê–î–ê–ù–ò–ï:
–ù–∞–ø–∏—à–∏—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—É, –∫–æ—Ç–æ—Ä–∞—è –ø–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –∏–∑ –≥—Ä–∞–¥—É—Å–æ–≤ –¶–µ–ª—å—Å–∏—è –≤ –§–∞—Ä–µ–Ω–≥–µ–π—Ç—ã. –§–æ—Ä–º—É–ª–∞: F = C * 9/5 + 32

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–û–¥–Ω–æ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ C (-100.0 ‚â§ C ‚â§ 100.0)

–í–´–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤ –§–∞—Ä–µ–Ω–≥–µ–π—Ç–∞—Ö —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é –¥–æ 1 –∑–Ω–∞–∫–∞ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π

–ü–†–ò–ú–ï–†:
–í—Ö–æ–¥:
25.0
–í—ã—Ö–æ–¥:
77.0

–ü–û–î–°–ö–ê–ó–ö–ê:
–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–∏–ø double –∏ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ç–æ—Ä %.1f –¥–ª—è –≤—ã–≤–æ–¥–∞.""",

            "1_3": """–¢–ï–ú–ê: –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
–°–õ–û–ñ–ù–û–°–¢–¨: –°–ª–æ–∂–Ω–∞—è

–ó–ê–î–ê–ù–ò–ï:
–ù–∞–ø–∏—à–∏—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—É, –∫–æ—Ç–æ—Ä–∞—è —Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–∏–∞–º–µ—Ç—Ä –∫—Ä—É–≥–∞ –∏ –≤—ã—á–∏—Å–ª—è–µ—Ç –µ–≥–æ –ø–ª–æ—â–∞–¥—å –∏ –ø–µ—Ä–∏–º–µ—Ç—Ä. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ œÄ = 3.14159

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–û–¥–Ω–æ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ d (0.1 ‚â§ d ‚â§ 1000.0)

–í–´–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–î–≤–µ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —á–∏—Å–ª–∞ - –ø–ª–æ—â–∞–¥—å –∏ –ø–µ—Ä–∏–º–µ—Ç—Ä —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª, —Å 2 –∑–Ω–∞–∫–∞–º–∏ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π

–ü–†–ò–ú–ï–†:
–í—Ö–æ–¥:
10.0
–í—ã—Ö–æ–¥:
78.54 31.42

–ü–û–î–°–ö–ê–ó–ö–ê:
–ü–ª–æ—â–∞–¥—å = œÄ*r¬≤, –ø–µ—Ä–∏–º–µ—Ç—Ä = œÄ*d. –ü–æ–º–Ω–∏—Ç–µ, —á—Ç–æ r = d/2.""",

            "4_1": """–¢–ï–ú–ê: –ú–∞—Å—Å–∏–≤—ã
–°–õ–û–ñ–ù–û–°–¢–¨: –õ–µ–≥–∫–∞—è

–ó–ê–î–ê–ù–ò–ï:
–ù–∞–ø–∏—à–∏—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—É, –∫–æ—Ç–æ—Ä–∞—è —Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–∞—Å—Å–∏–≤ –∏–∑ N —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª –∏ –Ω–∞—Ö–æ–¥–∏—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç.

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞: N (1 ‚â§ N ‚â§ 100)
–í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞: N —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª

–í–´–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∏–∑ –º–∞—Å—Å–∏–≤–∞

–ü–†–ò–ú–ï–†:
–í—Ö–æ–¥:
5
3 7 2 9 1
–í—ã—Ö–æ–¥:
9

–ü–û–î–°–ö–ê–ó–ö–ê:
–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –º–∞–∫—Å–∏–º—É–º –ø–µ—Ä–≤—ã–º —ç–ª–µ–º–µ–Ω—Ç–æ–º –º–∞—Å—Å–∏–≤–∞, –∑–∞—Ç–µ–º —Å—Ä–∞–≤–Ω–∏–≤–∞–π—Ç–µ —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏.""",

            "4_2": """–¢–ï–ú–ê: –ú–∞—Å—Å–∏–≤—ã
–°–õ–û–ñ–ù–û–°–¢–¨: –°—Ä–µ–¥–Ω—è—è

–ó–ê–î–ê–ù–ò–ï:
–ù–∞–ø–∏—à–∏—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—É, –∫–æ—Ç–æ—Ä–∞—è —Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–∞—Å—Å–∏–≤ —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª –∏ –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤, –±–æ–ª—å—à–∏—Ö —Å—Ä–µ–¥–Ω–µ–≥–æ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ.

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞: N (1 ‚â§ N ‚â§ 100)
–í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞: N —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª

–í–´–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –±–æ–ª—å—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ

–ü–†–ò–ú–ï–†:
–í—Ö–æ–¥:
5
1 2 3 4 5
–í—ã—Ö–æ–¥:
2

–ü–û–î–°–ö–ê–ó–ö–ê:
–°–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥–∏—Ç–µ —Å—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ, –∑–∞—Ç–µ–º –ø–µ—Ä–µ—Å—á–∏—Ç–∞–π—Ç–µ –º–∞—Å—Å–∏–≤.""",

            "4_3": """–¢–ï–ú–ê: –ú–∞—Å—Å–∏–≤—ã
–°–õ–û–ñ–ù–û–°–¢–¨: –°–ª–æ–∂–Ω–∞—è

–ó–ê–î–ê–ù–ò–ï:
–ù–∞–ø–∏—à–∏—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—É, –∫–æ—Ç–æ—Ä–∞—è —Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–≤–∞ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–∞—Å—Å–∏–≤–∞ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏—Ö –≤ –æ–¥–∏–Ω –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–∞—Å—Å–∏–≤ –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤.

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞: N (1 ‚â§ N ‚â§ 50)
–í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞: N –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª
–¢—Ä–µ—Ç—å—è —Å—Ç—Ä–æ–∫–∞: M (1 ‚â§ M ‚â§ 50)
–ß–µ—Ç–≤—ë—Ä—Ç–∞—è —Å—Ç—Ä–æ–∫–∞: M –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª

–í–´–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–û–¥–Ω–∞ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤) —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª

–ü–†–ò–ú–ï–†:
–í—Ö–æ–¥:
3
1 3 5
3
2 3 6
–í—ã—Ö–æ–¥:
1 2 3 5 6

–ü–û–î–°–ö–ê–ó–ö–ê:
–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–≤—É—Ö—É–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥ (two pointers) –¥–ª—è —Å–ª–∏—è–Ω–∏—è.""",

            "6_1": """–¢–ï–ú–ê: –£–∫–∞–∑–∞—Ç–µ–ª–∏
–°–õ–û–ñ–ù–û–°–¢–¨: –õ–µ–≥–∫–∞—è

–ó–ê–î–ê–ù–ò–ï:
–ù–∞–ø–∏—à–∏—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—É —Å —Ñ—É–Ω–∫—Ü–∏–µ–π, –∫–æ—Ç–æ—Ä–∞—è –º–µ–Ω—è–µ—Ç –º–µ—Å—Ç–∞–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è –¥–≤—É—Ö —Ü–µ–ª—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö, –∏—Å–ø–æ–ª—å–∑—É—è —É–∫–∞–∑–∞—Ç–µ–ª–∏.

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–î–≤–∞ —Ü–µ–ª—ã—Ö —á–∏—Å–ª–∞ a –∏ b

–í–´–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–ó–Ω–∞—á–µ–Ω–∏—è a –∏ b –ø–æ—Å–ª–µ –æ–±–º–µ–Ω–∞

–ü–†–ò–ú–ï–†:
–í—Ö–æ–¥:
10 20
–í—ã—Ö–æ–¥:
20 10

–ü–û–î–°–ö–ê–ó–ö–ê:
–°–æ–∑–¥–∞–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é swap(int *x, int *y) –∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é.""",

            "5_1": """–¢–ï–ú–ê: –§—É–Ω–∫—Ü–∏–∏
–°–õ–û–ñ–ù–û–°–¢–¨: –õ–µ–≥–∫–∞—è

–ó–ê–î–ê–ù–ò–ï:
–ù–∞–ø–∏—à–∏—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—É —Å —Ñ—É–Ω–∫—Ü–∏–µ–π factorial(int n), –∫–æ—Ç–æ—Ä–∞—è –≤—ã—á–∏—Å–ª—è–µ—Ç —Ñ–∞–∫—Ç–æ—Ä–∏–∞–ª —á–∏—Å–ª–∞ n.

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–û–¥–Ω–æ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ n (0 ‚â§ n ‚â§ 10)

–í–´–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–§–∞–∫—Ç–æ—Ä–∏–∞–ª —á–∏—Å–ª–∞ n

–ü–†–ò–ú–ï–†:
–í—Ö–æ–¥:
5
–í—ã—Ö–æ–¥:
120

–ü–û–î–°–ö–ê–ó–ö–ê:
–§–∞–∫—Ç–æ—Ä–∏–∞–ª n! = n * (n-1) * ... * 2 * 1. –£—á—Ç–∏—Ç–µ, —á—Ç–æ 0! = 1."""
        }

        docs = []
        for key, content in examples.items():
            topic_id, difficulty = key.split('_')
            doc = Document(
                page_content=content,
                metadata={
                    'source': f'built_in_example_{key}',
                    'type': 'task_example',
                    'topic_id': topic_id,
                    'difficulty': int(difficulty),
                    'language': 'russian'
                }
            )
            docs.append(doc)

        return docs

    def _load_external(self) -> List[Document]:
        """ Load external markdown files from the knowledge base directory """
        if not os.path.exists(self.knowledge_base_dir):
            return []

        try:
            loader = DirectoryLoader(
                self.knowledge_base_dir,
                glob="**/*.md",
                loader_cls=TextLoader,
                loader_kwargs={'encoding': 'utf-8'}
            )
            loaded = loader.load()
            for d in loaded:
                d.metadata.setdefault('source', 'external')
                d.metadata['type'] = 'external_knowledge'
            return loaded
        except Exception as e:
            logger.info(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–Ω–µ—à–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤: {e}")
            return []

    def _process_documents(self, documents: List[Document]) -> List[Document]:
        """ Process and split documents into chunks """
        # Specific separators for task documents
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n–ó–ê–î–ê–ù–ò–ï:", "\n\n–ü–†–ò–ú–ï–†:", "\n\n–ü–û–î–°–ö–ê–ó–ö–ê:", "\n\n", "\n"]
        )

        processed = []
        for doc in documents:
            content_hash = hashlib.md5(doc.page_content.encode()).hexdigest()
            doc.metadata['content_hash'] = content_hash
            chunks = text_splitter.split_documents([doc])
            processed.extend(chunks)

        return processed

    def load_or_create(self, index_name: str = "task_generation_faiss"):
        """Load existing vector store or create a new one."""
        index_path = os.path.join(self.vector_db_dir, index_name)

        # Try to load existing vector store
        if os.path.exists(index_path):
            try:
                logger.info(f"üìö –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –∏–∑ {index_path}...")
                return FAISS.load_local(
                    index_path,
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
            except Exception as e:
                logger.info(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É: {e}")
                logger.info("üèóÔ∏è –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É...")

        # Create new vector store
        base_docs = self._built_in_examples()
        external_docs = self._load_external()
        all_docs = base_docs + external_docs

        processed = self._process_documents(all_docs)

        if not processed:
            logger.info("‚ùå –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã!")
            return None

        logger.info(f"üìù –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(processed)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        vs = FAISS.from_documents(processed, self.embeddings)

        os.makedirs(index_path, exist_ok=True)
        vs.save_local(index_path)
        logger.info(f"‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {index_path}")

        return vs
