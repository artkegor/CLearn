# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XK7wIpvqFw5bCC-f2i4EaB2aEJ8ehw7G
"""

–í–æ–¥ –∫–∞–∫ —Å–æ–∑–¥–∞–≤–∞–ª–∏—Å—å —á–∞–Ω–∫–∏
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤—Å–µ PDF —Ñ–∞–π–ª—ã
uploaded = files.upload()

# –°–ø–∏—Å–æ–∫ –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
all_docs = []

# –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∫–∞–∂–¥—ã–π PDF
for filename in uploaded.keys():
    loader = PyPDFLoader(filename)
    docs = loader.load()
    all_docs.extend(docs)

print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_docs)} —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ {len(uploaded)} –∫–Ω–∏–≥")

from langchain_text_splitters import RecursiveCharacterTextSplitter

# –†–∞–∑–¥–µ–ª–∏—Ç–µ –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞ —á–∞–Ω–∫–∏
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)

chunks = text_splitter.split_documents(all_docs)
print(f"–°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤")

# ============ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï ============
if name == "main":
    print("üöÄ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ß–ê–ù–ö–û–í\n")

    # –£–±–µ–¥–∏—Å—å, —á—Ç–æ chunks —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã (—Ç–≤–æ–π –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥)
    # chunks –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≥–æ—Ç–æ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –ø–µ—Ä–µ–¥ —ç—Ç–∏–º

    if 'chunks' not in locals():
        print("‚ùå –û—à–∏–±–∫–∞: –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è 'chunks' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        print("–£–±–µ–¥–∏—Å—å, —á—Ç–æ —Ç—ã –∑–∞–≥—Ä—É–∑–∏–ª –∏ —Ä–∞–∑–±–∏–ª –¥–æ–∫—É–º–µ–Ω—Ç—ã –î–û —ç—Ç–æ–≥–æ –∫–æ–¥–∞")
        exit(1)

    # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞
    print("–í—ã–±–µ—Ä–∏ —Ä–µ–∂–∏–º:")
    print("1 - —Å –¥–≤–æ–π–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π (–º–µ–¥–ª–µ–Ω–Ω–æ, –Ω–æ —Ç–æ—á–Ω–µ–µ)")
    print("2 - —Ç–æ–ª—å–∫–æ Pass1 (–±—ã—Å—Ç—Ä–æ, –Ω–æ –º–µ–Ω–µ–µ —Ç–æ—á–Ω–æ)")
    mode = input("\n–¢–≤–æ–π –≤—ã–±–æ—Ä (1 –∏–ª–∏ 2): ").strip()
    validate_mode = mode != "2"

    # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π —á–∞–Ω–∫–∏
    classifier = ChunkClassifier(model=classifier_model, validate=validate_mode)
    classified_chunks = classifier.classify_chunks(chunks, verbose=True)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = classifier.get_statistics()
    print("\n" + "=" * 60)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò:")
    print("=" * 60)
    print(f"–í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {stats['total_chunks']}")
    print(f"Pass1 —Ç–æ—á–Ω–æ—Å—Ç—å: {stats['pass1_accuracy']}")
    print(f"–†–∞–∑–Ω–æ–≥–ª–∞—Å–∏–π: {stats['disagreements']} ({stats['disagreement_rate']})")
    print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–µ–º–∞–º:")
    for topic, count in stats['by_topic'].items():
        print(f"  {topic}: {count}")